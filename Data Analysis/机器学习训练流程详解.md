# 机器学习训练流程详解

在深度学习项目中，无论是使用 **PyTorch** 还是 **TensorFlow**，代码的执行流程都遵循相似的逻辑，均围绕 **数据**、**模型**、**训练**、**评估** 四大核心展开。PyTorch 的动态计算图适合研究与快速迭代，而 TensorFlow 的静态图在生产部署中更具优势。实际开发中，建议根据项目需求选择框架，并通过可视化工具（如 TensorBoard）监控训练过程。

## 一、模型训练的基本步骤

### 1. 数据准备

**目标**：将原始数据转化为模型**可训练的格式**，并高效加载。

#### 关键操作

- **数据加载**：
  - 图像数据：使用 `PIL`、`OpenCV` 或框架内置工具（如 `torchvision`、`tf.keras.preprocessing.image`）。
  - 结构化数据：通过 `pandas` 读取 CSV 文件。
  - 文本数据：使用 `torchtext` 或 `TensorFlow Datasets`。
- **数据预处理**：
  - 标准化：`(x - mean) / std`
  - 归一化：将数据缩放到 `[0, 1]`
  - 数据增强：随机翻转、旋转、裁剪（图像任务常用）。
- **数据管道构建**：

  ```python
  # PyTorch
  from torch.utils.data import DataLoader, Dataset
  train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)

  # TensorFlow
  import tensorflow as tf
  dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
  dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)
  ```

### 2. 模型构建

**目标**：定义网络结构，明确参数初始化方式。

#### 关键操作

- **选择模型类型**：
  - CNN：适用于图像任务（如 `ResNet`、`VGG`）。
  - RNN/Transformer：适用于序列数据（如文本、时间序列）。
- **定义网络层**：

  ```python
  # PyTorch
  import torch.nn as nn
  class Net(nn.Module):
      def __init__(self):
          super().__init__()
          self.layer = nn.Sequential(
              nn.Conv2d(1, 32, 3, 1),
              nn.ReLU(),
              nn.Linear(32*26*26, 10)
          )

  # TensorFlow
  import tensorflow as tf
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28,28,1)),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(10)
  ])
  ```

### 3. 配置训练组件

**目标**：设置损失函数、优化器和评估指标。

#### 关键操作

- **损失函数**：
  - 分类任务：交叉熵损失（`CrossEntropyLoss`）。
  - 回归任务：均方误差（`MSELoss`）。
- **优化器**：
  - 常用优化器：`Adam`（自适应学习率）、`SGD`（动量加速）。
  - 学习率调度器：`StepLR`、`CosineAnnealingLR`（PyTorch）或 `tf.keras.callbacks.LearningRateScheduler`（TensorFlow）。
- **评估指标**：
  - 分类任务：准确率（Accuracy）、F1 Score。
  - 目标检测：mAP（Mean Average Precision）。

### 4. 训练循环

**目标**：通过迭代数据更新模型参数。

#### 关键操作

- **PyTorch 训练循环**：

  ```python
  for epoch in range(epochs):
      model.train()
      for inputs, labels in train_loader:
          outputs = model(inputs)         # 前向传播
          loss = criterion(outputs, labels) # 计算损失
          optimizer.zero_grad()           # 梯度清零
          loss.backward()                 # 反向传播
          optimizer.step()                # 更新参数
  ```

- **TensorFlow 训练循环**：

  ```python
  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
  history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)
  ```

### 5. 模型评估与调优

**目标**：验证模型性能，防止过拟合。

#### 关键操作

- **验证集评估**：

  ```python
  # PyTorch
  model.eval()
  with torch.no_grad():
      for inputs, labels in val_loader:
          outputs = model(inputs)
          val_loss += criterion(outputs, labels).item()

  # TensorFlow
  loss, accuracy = model.evaluate(val_dataset)
  ```

- **早停法（Early Stopping）**：

  ```python
  # TensorFlow
  callback = tf.keras.callbacks.EarlyStopping(patience=3)
  model.fit(..., callbacks=[callback])
  ```

### 6. 模型保存与部署

**目标**：持久化模型并部署到生产环境。

#### 关键操作

- **保存模型**：

  ```python
  # PyTorch
  torch.save(model.state_dict(), 'model.pth')

  # TensorFlow
  model.save('model.h5')  # 或 SavedModel 格式
  ```

- **部署推理**：

  ```python
  # PyTorch
  model.load_state_dict(torch.load('model.pth'))
  predictions = model(test_inputs).argmax(dim=1)

  # TensorFlow
  model = tf.keras.models.load_model('model.h5')
  predictions = model.predict(test_inputs)
  ```

## 二、完整代码模板

### PyTorch 模板

```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset

# 1. 自定义数据集
class CustomDataset(Dataset):
    def __init__(self, data, labels):
        self.data = data
        self.labels = labels

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

# 2. 定义模型
class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = nn.Linear(784, 10)

    def forward(self, x):
        return self.fc(x)

# 3. 训练流程
def train():
    # 数据准备
    dataset = CustomDataset(data, labels)
    train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

    # 模型、损失函数、优化器
    model = Net()
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    # 训练循环
    for epoch in range(10):
        model.train()
        for inputs, labels in train_loader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        print(f'Epoch {epoch+1}, Loss: {loss.item()}')

if __name__ == '__main__':
    train()
```

### TensorFlow 模板

```python
import tensorflow as tf
from tensorflow.keras import layers

# 1. 数据准备
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = x_train.astype('float32') / 255
x_test = x_test.astype('float32') / 255

# 2. 构建模型
model = tf.keras.Sequential([
    layers.Flatten(input_shape=(28, 28)),
    layers.Dense(128, activation='relu'),
    layers.Dense(10)
])

# 3. 配置训练参数
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# 4. 训练与评估
history = model.fit(x_train, y_train, epochs=10, validation_split=0.2)
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f'Test Accuracy: {test_acc}')

# 5. 保存模型
model.save('mnist_model.h5')
```
